INFO:numexpr.utils:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO:numexpr.utils:NumExpr defaulting to 8 threads.
/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Using device: cuda
Loaded pretrained weights with message: _IncompatibleKeys(missing_keys=['patch_norm.weight', 'patch_norm.bias', 'year_embedding.weight', 'year_proj.weight', 'year_proj.bias', 'regression_head.0.weight', 'regression_head.0.bias', 'regression_head.1.weight', 'regression_head.1.bias', 'regression_head.4.weight', 'regression_head.4.bias', 'regression_head.7.weight', 'regression_head.7.bias', 'regression_head.8.weight', 'regression_head.8.bias'], unexpected_keys=[])
Model created successfully

Creating training dataloaders...

Initializing Training Dataset:
Sentinel data path: /mnt/guanabana/raid/shared/dropbox/QinLennart/training_subset_normalized/monthly
Ground truth path: /mnt/guanabana/raid/shared/dropbox/QinLennart/training_subset_gt

First few unique IDs:
- 2753185_2015-07
- 2753185_2015-08
- 2753185_2015-09
- 2753185_2015-10
- 2753185_2015-11
Found 11340 unique location-time pairs for monthly training data

Initializing Training Dataset:
Sentinel data path: /mnt/guanabana/raid/shared/dropbox/QinLennart/training_subset_normalized/yearly
Ground truth path: /mnt/guanabana/raid/shared/dropbox/QinLennart/training_subset_gt

First few unique IDs:
- 2753185_2015
- 2753185_2016
- 2753185_2017
- 2753185_2018
- 2753198_2015
Found 1080 unique location-time pairs for yearly training data
Number of training locations: 229
Number of validation locations: 41
Initialized trainer. Training results will be saved to: vit_test_results_20241231_125704

Starting training for 100 epochs...

Epoch 1/100
Epoch 1:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Epoch 1:   0%|          | 0/29 [00:08<?, ?it/s, loss=0.4818, lr=0.000000]Epoch 1:   3%|▎         | 1/29 [00:08<03:53,  8.35s/it, loss=0.4818, lr=0.000000]Epoch 1:   3%|▎         | 1/29 [00:08<03:53,  8.35s/it, loss=0.4677, lr=0.000000]Epoch 1:   7%|▋         | 2/29 [00:08<01:38,  3.66s/it, loss=0.4677, lr=0.000000]Epoch 1:   7%|▋         | 2/29 [00:09<01:38,  3.66s/it, loss=0.4878, lr=0.000000]Epoch 1:  10%|█         | 3/29 [00:09<00:58,  2.25s/it, loss=0.4878, lr=0.000000]Epoch 1:  10%|█         | 3/29 [00:10<00:58,  2.25s/it, loss=0.4748, lr=0.000000]Epoch 1:  14%|█▍        | 4/29 [00:10<00:41,  1.65s/it, loss=0.4748, lr=0.000000]Epoch 1:  14%|█▍        | 4/29 [00:12<00:41,  1.65s/it, loss=0.4749, lr=0.000000]Epoch 1:  17%|█▋        | 5/29 [00:12<00:43,  1.80s/it, loss=0.4749, lr=0.000000]Epoch 1:  17%|█▋        | 5/29 [00:12<00:43,  1.80s/it, loss=0.4727, lr=0.000000]Epoch 1:  21%|██        | 6/29 [00:12<00:34,  1.49s/it, loss=0.4727, lr=0.000000]Epoch 1:  21%|██        | 6/29 [00:13<00:34,  1.49s/it, loss=0.4732, lr=0.000000]Epoch 1:  24%|██▍       | 7/29 [00:13<00:27,  1.25s/it, loss=0.4732, lr=0.000000]Epoch 1:  24%|██▍       | 7/29 [00:14<00:27,  1.25s/it, loss=0.4718, lr=0.000000]Epoch 1:  28%|██▊       | 8/29 [00:14<00:23,  1.10s/it, loss=0.4718, lr=0.000000]Epoch 1:  28%|██▊       | 8/29 [00:18<00:23,  1.10s/it, loss=0.4831, lr=0.000000]Epoch 1:  31%|███       | 9/29 [00:18<00:38,  1.95s/it, loss=0.4831, lr=0.000000]Epoch 1:  31%|███       | 9/29 [00:19<00:38,  1.95s/it, loss=0.4689, lr=0.000000]Epoch 1:  34%|███▍      | 10/29 [00:19<00:32,  1.73s/it, loss=0.4689, lr=0.000000]Epoch 1:  34%|███▍      | 10/29 [00:20<00:32,  1.73s/it, loss=0.4839, lr=0.000000]Epoch 1:  38%|███▊      | 11/29 [00:20<00:25,  1.43s/it, loss=0.4839, lr=0.000000]Epoch 1:  38%|███▊      | 11/29 [00:20<00:25,  1.43s/it, loss=0.4741, lr=0.000000]Epoch 1:  41%|████▏     | 12/29 [00:20<00:19,  1.13s/it, loss=0.4741, lr=0.000000]Epoch 1:  41%|████▏     | 12/29 [00:24<00:19,  1.13s/it, loss=0.4684, lr=0.000000]Epoch 1:  45%|████▍     | 13/29 [00:24<00:32,  2.01s/it, loss=0.4684, lr=0.000000]Epoch 1:  45%|████▍     | 13/29 [00:25<00:32,  2.01s/it, loss=0.4690, lr=0.000000]Epoch 1:  48%|████▊     | 14/29 [00:25<00:24,  1.65s/it, loss=0.4690, lr=0.000000]Epoch 1:  48%|████▊     | 14/29 [00:26<00:24,  1.65s/it, loss=0.4700, lr=0.000000]Epoch 1:  52%|█████▏    | 15/29 [00:26<00:19,  1.38s/it, loss=0.4700, lr=0.000000]Epoch 1:  52%|█████▏    | 15/29 [00:27<00:19,  1.38s/it, loss=0.4759, lr=0.000000]Epoch 1:  55%|█████▌    | 16/29 [00:27<00:15,  1.17s/it, loss=0.4759, lr=0.000000]Epoch 1:  55%|█████▌    | 16/29 [00:30<00:15,  1.17s/it, loss=0.4670, lr=0.000000]Epoch 1:  59%|█████▊    | 17/29 [00:31<00:24,  2.00s/it, loss=0.4670, lr=0.000000]Epoch 1:  59%|█████▊    | 17/29 [00:31<00:24,  2.00s/it, loss=0.4810, lr=0.000000]Epoch 1:  62%|██████▏   | 18/29 [00:31<00:17,  1.62s/it, loss=0.4810, lr=0.000000]Epoch 1:  62%|██████▏   | 18/29 [00:32<00:17,  1.62s/it, loss=0.4711, lr=0.000000]Epoch 1:  66%|██████▌   | 19/29 [00:32<00:13,  1.35s/it, loss=0.4711, lr=0.000000]Epoch 1:  66%|██████▌   | 19/29 [00:33<00:13,  1.35s/it, loss=0.4752, lr=0.000000]Epoch 1:  69%|██████▉   | 20/29 [00:33<00:10,  1.11s/it, loss=0.4752, lr=0.000000]Epoch 1:  69%|██████▉   | 20/29 [00:37<00:10,  1.11s/it, loss=0.4590, lr=0.000000]Epoch 1:  72%|███████▏  | 21/29 [00:37<00:16,  2.03s/it, loss=0.4590, lr=0.000000]Epoch 1:  72%|███████▏  | 21/29 [00:38<00:16,  2.03s/it, loss=0.4761, lr=0.000000]Epoch 1:  76%|███████▌  | 22/29 [00:38<00:11,  1.70s/it, loss=0.4761, lr=0.000000]Epoch 1:  76%|███████▌  | 22/29 [00:38<00:11,  1.70s/it, loss=0.4663, lr=0.000000]Epoch 1:  79%|███████▉  | 23/29 [00:38<00:08,  1.41s/it, loss=0.4663, lr=0.000000]Epoch 1:  79%|███████▉  | 23/29 [00:39<00:08,  1.41s/it, loss=0.4734, lr=0.000000]Epoch 1:  83%|████████▎ | 24/29 [00:39<00:06,  1.25s/it, loss=0.4734, lr=0.000000]Epoch 1:  83%|████████▎ | 24/29 [00:42<00:06,  1.25s/it, loss=0.4711, lr=0.000000]Epoch 1:  86%|████████▌ | 25/29 [00:42<00:07,  1.84s/it, loss=0.4711, lr=0.000000]Epoch 1:  86%|████████▌ | 25/29 [00:43<00:07,  1.84s/it, loss=0.4794, lr=0.000000]Epoch 1:  90%|████████▉ | 26/29 [00:43<00:04,  1.37s/it, loss=0.4794, lr=0.000000]Epoch 1:  90%|████████▉ | 26/29 [00:43<00:04,  1.37s/it, loss=0.4720, lr=0.000000]Epoch 1:  93%|█████████▎| 27/29 [00:43<00:02,  1.04s/it, loss=0.4720, lr=0.000000]Epoch 1:  93%|█████████▎| 27/29 [00:43<00:02,  1.04s/it, loss=0.4881, lr=0.000000]Epoch 1:  97%|█████████▋| 28/29 [00:43<00:00,  1.21it/s, loss=0.4881, lr=0.000000]Epoch 1:  97%|█████████▋| 28/29 [00:44<00:00,  1.21it/s, loss=0.4760, lr=0.000000]Epoch 1: 100%|██████████| 29/29 [00:44<00:00,  1.17it/s, loss=0.4760, lr=0.000000]Epoch 1: 100%|██████████| 29/29 [00:44<00:00,  1.55s/it, loss=0.4760, lr=0.000000]
Train Loss: 0.4743
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196
Saved checkpoint to vit_test_results_20241231_125704/checkpoint_epoch_1.pth
Saved best model with loss: 0.4743

Epoch 2/100
Epoch 2:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 2:   0%|          | 0/29 [00:06<?, ?it/s, loss=0.4717, lr=0.000000]Epoch 2:   3%|▎         | 1/29 [00:06<03:08,  6.73s/it, loss=0.4717, lr=0.000000]Epoch 2:   3%|▎         | 1/29 [00:07<03:08,  6.73s/it, loss=0.4728, lr=0.000000]Epoch 2:   7%|▋         | 2/29 [00:07<01:27,  3.25s/it, loss=0.4728, lr=0.000000]Epoch 2:   7%|▋         | 2/29 [00:08<01:27,  3.25s/it, loss=0.4723, lr=0.000000]Epoch 2:  10%|█         | 3/29 [00:08<00:53,  2.06s/it, loss=0.4723, lr=0.000000]Epoch 2:  10%|█         | 3/29 [00:08<00:53,  2.06s/it, loss=0.4862, lr=0.000000]Epoch 2:  14%|█▍        | 4/29 [00:08<00:38,  1.54s/it, loss=0.4862, lr=0.000000]Epoch 2:  14%|█▍        | 4/29 [00:12<00:38,  1.54s/it, loss=0.4709, lr=0.000000]Epoch 2:  17%|█▋        | 5/29 [00:12<00:58,  2.44s/it, loss=0.4709, lr=0.000000]Epoch 2:  17%|█▋        | 5/29 [00:13<00:58,  2.44s/it, loss=0.4833, lr=0.000000]Epoch 2:  21%|██        | 6/29 [00:13<00:42,  1.84s/it, loss=0.4833, lr=0.000000]Epoch 2:  21%|██        | 6/29 [00:14<00:42,  1.84s/it, loss=0.4698, lr=0.000000]Epoch 2:  24%|██▍       | 7/29 [00:14<00:32,  1.46s/it, loss=0.4698, lr=0.000000]Epoch 2:  24%|██▍       | 7/29 [00:14<00:32,  1.46s/it, loss=0.4820, lr=0.000000]Epoch 2:  28%|██▊       | 8/29 [00:14<00:24,  1.17s/it, loss=0.4820, lr=0.000000]Epoch 2:  28%|██▊       | 8/29 [00:18<00:24,  1.17s/it, loss=0.4670, lr=0.000000]Epoch 2:  31%|███       | 9/29 [00:18<00:39,  1.95s/it, loss=0.4670, lr=0.000000]Epoch 2:  31%|███       | 9/29 [00:19<00:39,  1.95s/it, loss=0.4818, lr=0.000000]Epoch 2:  34%|███▍      | 10/29 [00:19<00:29,  1.57s/it, loss=0.4818, lr=0.000000]Epoch 2:  34%|███▍      | 10/29 [00:19<00:29,  1.57s/it, loss=0.4715, lr=0.000000]Epoch 2:  38%|███▊      | 11/29 [00:19<00:23,  1.30s/it, loss=0.4715, lr=0.000000]Epoch 2:  38%|███▊      | 11/29 [00:20<00:23,  1.30s/it, loss=0.4780, lr=0.000000]Epoch 2:  41%|████▏     | 12/29 [00:20<00:18,  1.11s/it, loss=0.4780, lr=0.000000]Epoch 2:  41%|████▏     | 12/29 [00:24<00:18,  1.11s/it, loss=0.4771, lr=0.000000]Epoch 2:  45%|████▍     | 13/29 [00:24<00:31,  1.99s/it, loss=0.4771, lr=0.000000]Epoch 2:  45%|████▍     | 13/29 [00:25<00:31,  1.99s/it, loss=0.4770, lr=0.000000]Epoch 2:  48%|████▊     | 14/29 [00:25<00:24,  1.61s/it, loss=0.4770, lr=0.000000]Epoch 2:  48%|████▊     | 14/29 [00:26<00:24,  1.61s/it, loss=0.4740, lr=0.000000]Epoch 2:  52%|█████▏    | 15/29 [00:26<00:19,  1.37s/it, loss=0.4740, lr=0.000000]Epoch 2:  52%|█████▏    | 15/29 [00:26<00:19,  1.37s/it, loss=0.4757, lr=0.000000]Epoch 2:  55%|█████▌    | 16/29 [00:26<00:13,  1.07s/it, loss=0.4757, lr=0.000000]Epoch 2:  55%|█████▌    | 16/29 [00:30<00:13,  1.07s/it, loss=0.4717, lr=0.000000]Epoch 2:  59%|█████▊    | 17/29 [00:30<00:23,  1.94s/it, loss=0.4717, lr=0.000000]Epoch 2:  59%|█████▊    | 17/29 [00:31<00:23,  1.94s/it, loss=0.4649, lr=0.000000]Epoch 2:  62%|██████▏   | 18/29 [00:31<00:17,  1.61s/it, loss=0.4649, lr=0.000000]Epoch 2:  62%|██████▏   | 18/29 [00:32<00:17,  1.61s/it, loss=0.4692, lr=0.000000]Epoch 2:  66%|██████▌   | 19/29 [00:32<00:13,  1.34s/it, loss=0.4692, lr=0.000000]Epoch 2:  66%|██████▌   | 19/29 [00:32<00:13,  1.34s/it, loss=0.4633, lr=0.000000]Epoch 2:  69%|██████▉   | 20/29 [00:32<00:10,  1.17s/it, loss=0.4633, lr=0.000000]Epoch 2:  69%|██████▉   | 20/29 [00:37<00:10,  1.17s/it, loss=0.4833, lr=0.000000]Epoch 2:  72%|███████▏  | 21/29 [00:37<00:16,  2.07s/it, loss=0.4833, lr=0.000000]Epoch 2:  72%|███████▏  | 21/29 [00:37<00:16,  2.07s/it, loss=0.4819, lr=0.000000]Epoch 2:  76%|███████▌  | 22/29 [00:37<00:11,  1.68s/it, loss=0.4819, lr=0.000000]Epoch 2:  76%|███████▌  | 22/29 [00:38<00:11,  1.68s/it, loss=0.4816, lr=0.000000]Epoch 2:  79%|███████▉  | 23/29 [00:38<00:07,  1.33s/it, loss=0.4816, lr=0.000000]Epoch 2:  79%|███████▉  | 23/29 [00:38<00:07,  1.33s/it, loss=0.4661, lr=0.000000]Epoch 2:  83%|████████▎ | 24/29 [00:38<00:05,  1.13s/it, loss=0.4661, lr=0.000000]Epoch 2:  83%|████████▎ | 24/29 [00:43<00:05,  1.13s/it, loss=0.4710, lr=0.000000]Epoch 2:  86%|████████▌ | 25/29 [00:43<00:08,  2.13s/it, loss=0.4710, lr=0.000000]Epoch 2:  86%|████████▌ | 25/29 [00:43<00:08,  2.13s/it, loss=0.4781, lr=0.000000]Epoch 2:  90%|████████▉ | 26/29 [00:43<00:04,  1.58s/it, loss=0.4781, lr=0.000000]Epoch 2:  90%|████████▉ | 26/29 [00:43<00:04,  1.58s/it, loss=0.4665, lr=0.000000]Epoch 2:  93%|█████████▎| 27/29 [00:43<00:02,  1.19s/it, loss=0.4665, lr=0.000000]Epoch 2:  93%|█████████▎| 27/29 [00:44<00:02,  1.19s/it, loss=0.4742, lr=0.000000]Epoch 2:  97%|█████████▋| 28/29 [00:44<00:00,  1.09it/s, loss=0.4742, lr=0.000000]Epoch 2:  97%|█████████▋| 28/29 [00:44<00:00,  1.09it/s, loss=0.4703, lr=0.000000]Epoch 2: 100%|██████████| 29/29 [00:44<00:00,  1.39it/s, loss=0.4703, lr=0.000000]Epoch 2: 100%|██████████| 29/29 [00:44<00:00,  1.54s/it, loss=0.4703, lr=0.000000]
Train Loss: 0.4742
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196

Epoch 3/100
Epoch 3:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 3:   0%|          | 0/29 [00:07<?, ?it/s, loss=0.4818, lr=0.000000]Epoch 3:   3%|▎         | 1/29 [00:07<03:18,  7.08s/it, loss=0.4818, lr=0.000000]Epoch 3:   3%|▎         | 1/29 [00:07<03:18,  7.08s/it, loss=0.4710, lr=0.000000]Epoch 3:   7%|▋         | 2/29 [00:07<01:28,  3.29s/it, loss=0.4710, lr=0.000000]Epoch 3:   7%|▋         | 2/29 [00:08<01:28,  3.29s/it, loss=0.4710, lr=0.000000]Epoch 3:  10%|█         | 3/29 [00:08<00:55,  2.13s/it, loss=0.4710, lr=0.000000]Epoch 3:  10%|█         | 3/29 [00:09<00:55,  2.13s/it, loss=0.4744, lr=0.000000]Epoch 3:  14%|█▍        | 4/29 [00:09<00:37,  1.51s/it, loss=0.4744, lr=0.000000]Epoch 3:  14%|█▍        | 4/29 [00:12<00:37,  1.51s/it, loss=0.4849, lr=0.000000]Epoch 3:  17%|█▋        | 5/29 [00:12<00:51,  2.17s/it, loss=0.4849, lr=0.000000]Epoch 3:  17%|█▋        | 5/29 [00:12<00:51,  2.17s/it, loss=0.4784, lr=0.000000]Epoch 3:  21%|██        | 6/29 [00:12<00:37,  1.62s/it, loss=0.4784, lr=0.000000]Epoch 3:  21%|██        | 6/29 [00:13<00:37,  1.62s/it, loss=0.4660, lr=0.000000]Epoch 3:  24%|██▍       | 7/29 [00:13<00:29,  1.32s/it, loss=0.4660, lr=0.000000]Epoch 3:  24%|██▍       | 7/29 [00:14<00:29,  1.32s/it, loss=0.4744, lr=0.000000]Epoch 3:  28%|██▊       | 8/29 [00:14<00:23,  1.10s/it, loss=0.4744, lr=0.000000]Epoch 3:  28%|██▊       | 8/29 [00:18<00:23,  1.10s/it, loss=0.4935, lr=0.000000]Epoch 3:  31%|███       | 9/29 [00:18<00:41,  2.07s/it, loss=0.4935, lr=0.000000]Epoch 3:  31%|███       | 9/29 [00:19<00:41,  2.07s/it, loss=0.4709, lr=0.000000]Epoch 3:  34%|███▍      | 10/29 [00:19<00:31,  1.64s/it, loss=0.4709, lr=0.000000]Epoch 3:  34%|███▍      | 10/29 [00:19<00:31,  1.64s/it, loss=0.4661, lr=0.000000]Epoch 3:  38%|███▊      | 11/29 [00:19<00:24,  1.35s/it, loss=0.4661, lr=0.000000]Epoch 3:  38%|███▊      | 11/29 [00:20<00:24,  1.35s/it, loss=0.4897, lr=0.000000]Epoch 3:  41%|████▏     | 12/29 [00:20<00:19,  1.13s/it, loss=0.4897, lr=0.000000]Epoch 3:  41%|████▏     | 12/29 [00:24<00:19,  1.13s/it, loss=0.4734, lr=0.000000]Epoch 3:  45%|████▍     | 13/29 [00:24<00:34,  2.13s/it, loss=0.4734, lr=0.000000]Epoch 3:  45%|████▍     | 13/29 [00:25<00:34,  2.13s/it, loss=0.4706, lr=0.000000]Epoch 3:  48%|████▊     | 14/29 [00:25<00:26,  1.74s/it, loss=0.4706, lr=0.000000]Epoch 3:  48%|████▊     | 14/29 [00:26<00:26,  1.74s/it, loss=0.4660, lr=0.000000]Epoch 3:  52%|█████▏    | 15/29 [00:26<00:20,  1.44s/it, loss=0.4660, lr=0.000000]Epoch 3:  52%|█████▏    | 15/29 [00:26<00:20,  1.44s/it, loss=0.4712, lr=0.000000]Epoch 3:  55%|█████▌    | 16/29 [00:26<00:14,  1.15s/it, loss=0.4712, lr=0.000000]Epoch 3:  55%|█████▌    | 16/29 [00:30<00:14,  1.15s/it, loss=0.4668, lr=0.000000]Epoch 3:  59%|█████▊    | 17/29 [00:30<00:22,  1.83s/it, loss=0.4668, lr=0.000000]Epoch 3:  59%|█████▊    | 17/29 [00:31<00:22,  1.83s/it, loss=0.4806, lr=0.000000]Epoch 3:  62%|██████▏   | 18/29 [00:31<00:16,  1.54s/it, loss=0.4806, lr=0.000000]Epoch 3:  62%|██████▏   | 18/29 [00:31<00:16,  1.54s/it, loss=0.4768, lr=0.000000]Epoch 3:  66%|██████▌   | 19/29 [00:31<00:12,  1.29s/it, loss=0.4768, lr=0.000000]Epoch 3:  66%|██████▌   | 19/29 [00:32<00:12,  1.29s/it, loss=0.4689, lr=0.000000]Epoch 3:  69%|██████▉   | 20/29 [00:32<00:08,  1.00it/s, loss=0.4689, lr=0.000000]Epoch 3:  69%|██████▉   | 20/29 [00:35<00:08,  1.00it/s, loss=0.4661, lr=0.000000]Epoch 3:  72%|███████▏  | 21/29 [00:35<00:13,  1.69s/it, loss=0.4661, lr=0.000000]Epoch 3:  72%|███████▏  | 21/29 [00:36<00:13,  1.69s/it, loss=0.4827, lr=0.000000]Epoch 3:  76%|███████▌  | 22/29 [00:36<00:09,  1.41s/it, loss=0.4827, lr=0.000000]Epoch 3:  76%|███████▌  | 22/29 [00:37<00:09,  1.41s/it, loss=0.4694, lr=0.000000]Epoch 3:  79%|███████▉  | 23/29 [00:37<00:07,  1.20s/it, loss=0.4694, lr=0.000000]Epoch 3:  79%|███████▉  | 23/29 [00:37<00:07,  1.20s/it, loss=0.4676, lr=0.000000]Epoch 3:  83%|████████▎ | 24/29 [00:37<00:05,  1.05s/it, loss=0.4676, lr=0.000000]Epoch 3:  83%|████████▎ | 24/29 [00:41<00:05,  1.05s/it, loss=0.4656, lr=0.000000]Epoch 3:  86%|████████▌ | 25/29 [00:41<00:07,  1.83s/it, loss=0.4656, lr=0.000000]Epoch 3:  86%|████████▌ | 25/29 [00:41<00:07,  1.83s/it, loss=0.4769, lr=0.000000]Epoch 3:  90%|████████▉ | 26/29 [00:41<00:04,  1.38s/it, loss=0.4769, lr=0.000000]Epoch 3:  90%|████████▉ | 26/29 [00:41<00:04,  1.38s/it, loss=0.4816, lr=0.000000]Epoch 3:  93%|█████████▎| 27/29 [00:41<00:02,  1.05s/it, loss=0.4816, lr=0.000000]Epoch 3:  93%|█████████▎| 27/29 [00:42<00:02,  1.05s/it, loss=0.4702, lr=0.000000]Epoch 3:  97%|█████████▋| 28/29 [00:42<00:00,  1.23it/s, loss=0.4702, lr=0.000000]Epoch 3:  97%|█████████▋| 28/29 [00:43<00:00,  1.23it/s, loss=0.4761, lr=0.000000]Epoch 3: 100%|██████████| 29/29 [00:43<00:00,  1.15it/s, loss=0.4761, lr=0.000000]Epoch 3: 100%|██████████| 29/29 [00:43<00:00,  1.49s/it, loss=0.4761, lr=0.000000]
Train Loss: 0.4742
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196

Epoch 4/100
Epoch 4:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 4:   0%|          | 0/29 [00:06<?, ?it/s, loss=0.4761, lr=0.000000]Epoch 4:   3%|▎         | 1/29 [00:06<02:52,  6.14s/it, loss=0.4761, lr=0.000000]Epoch 4:   3%|▎         | 1/29 [00:06<02:52,  6.14s/it, loss=0.4749, lr=0.000000]Epoch 4:   7%|▋         | 2/29 [00:06<01:19,  2.94s/it, loss=0.4749, lr=0.000000]Epoch 4:   7%|▋         | 2/29 [00:07<01:19,  2.94s/it, loss=0.4789, lr=0.000000]Epoch 4:  10%|█         | 3/29 [00:07<00:47,  1.82s/it, loss=0.4789, lr=0.000000]Epoch 4:  10%|█         | 3/29 [00:08<00:47,  1.82s/it, loss=0.4730, lr=0.000000]Epoch 4:  14%|█▍        | 4/29 [00:08<00:35,  1.40s/it, loss=0.4730, lr=0.000000]Epoch 4:  14%|█▍        | 4/29 [00:12<00:35,  1.40s/it, loss=0.4784, lr=0.000000]Epoch 4:  17%|█▋        | 5/29 [00:12<01:00,  2.52s/it, loss=0.4784, lr=0.000000]Epoch 4:  17%|█▋        | 5/29 [00:13<01:00,  2.52s/it, loss=0.4788, lr=0.000000]Epoch 4:  21%|██        | 6/29 [00:13<00:43,  1.89s/it, loss=0.4788, lr=0.000000]Epoch 4:  21%|██        | 6/29 [00:13<00:43,  1.89s/it, loss=0.4651, lr=0.000000]Epoch 4:  24%|██▍       | 7/29 [00:13<00:32,  1.47s/it, loss=0.4651, lr=0.000000]Epoch 4:  24%|██▍       | 7/29 [00:14<00:32,  1.47s/it, loss=0.4791, lr=0.000000]Epoch 4:  28%|██▊       | 8/29 [00:14<00:24,  1.19s/it, loss=0.4791, lr=0.000000]Epoch 4:  28%|██▊       | 8/29 [00:18<00:24,  1.19s/it, loss=0.4844, lr=0.000000]Epoch 4:  31%|███       | 9/29 [00:18<00:42,  2.11s/it, loss=0.4844, lr=0.000000]Epoch 4:  31%|███       | 9/29 [00:19<00:42,  2.11s/it, loss=0.4744, lr=0.000000]Epoch 4:  34%|███▍      | 10/29 [00:19<00:31,  1.67s/it, loss=0.4744, lr=0.000000]Epoch 4:  34%|███▍      | 10/29 [00:20<00:31,  1.67s/it, loss=0.4722, lr=0.000000]Epoch 4:  38%|███▊      | 11/29 [00:20<00:25,  1.40s/it, loss=0.4722, lr=0.000000]Epoch 4:  38%|███▊      | 11/29 [00:20<00:25,  1.40s/it, loss=0.4733, lr=0.000000]Epoch 4:  41%|████▏     | 12/29 [00:20<00:19,  1.15s/it, loss=0.4733, lr=0.000000]Epoch 4:  41%|████▏     | 12/29 [00:24<00:19,  1.15s/it, loss=0.4659, lr=0.000000]Epoch 4:  45%|████▍     | 13/29 [00:24<00:31,  1.98s/it, loss=0.4659, lr=0.000000]Epoch 4:  45%|████▍     | 13/29 [00:25<00:31,  1.98s/it, loss=0.4762, lr=0.000000]Epoch 4:  48%|████▊     | 14/29 [00:25<00:25,  1.68s/it, loss=0.4762, lr=0.000000]Epoch 4:  48%|████▊     | 14/29 [00:26<00:25,  1.68s/it, loss=0.4688, lr=0.000000]Epoch 4:  52%|█████▏    | 15/29 [00:26<00:19,  1.39s/it, loss=0.4688, lr=0.000000]Epoch 4:  52%|█████▏    | 15/29 [00:26<00:19,  1.39s/it, loss=0.4807, lr=0.000000]Epoch 4:  55%|█████▌    | 16/29 [00:26<00:15,  1.19s/it, loss=0.4807, lr=0.000000]Epoch 4:  55%|█████▌    | 16/29 [00:30<00:15,  1.19s/it, loss=0.4724, lr=0.000000]Epoch 4:  59%|█████▊    | 17/29 [00:30<00:23,  1.96s/it, loss=0.4724, lr=0.000000]Epoch 4:  59%|█████▊    | 17/29 [00:31<00:23,  1.96s/it, loss=0.4775, lr=0.000000]Epoch 4:  62%|██████▏   | 18/29 [00:31<00:16,  1.52s/it, loss=0.4775, lr=0.000000]Epoch 4:  62%|██████▏   | 18/29 [00:31<00:16,  1.52s/it, loss=0.4704, lr=0.000000]Epoch 4:  66%|██████▌   | 19/29 [00:31<00:12,  1.26s/it, loss=0.4704, lr=0.000000]Epoch 4:  66%|██████▌   | 19/29 [00:32<00:12,  1.26s/it, loss=0.4697, lr=0.000000]Epoch 4:  69%|██████▉   | 20/29 [00:32<00:10,  1.12s/it, loss=0.4697, lr=0.000000]Epoch 4:  69%|██████▉   | 20/29 [00:37<00:10,  1.12s/it, loss=0.4667, lr=0.000000]Epoch 4:  72%|███████▏  | 21/29 [00:37<00:17,  2.20s/it, loss=0.4667, lr=0.000000]Epoch 4:  72%|███████▏  | 21/29 [00:38<00:17,  2.20s/it, loss=0.4728, lr=0.000000]Epoch 4:  76%|███████▌  | 22/29 [00:38<00:12,  1.75s/it, loss=0.4728, lr=0.000000]Epoch 4:  76%|███████▌  | 22/29 [00:38<00:12,  1.75s/it, loss=0.4712, lr=0.000000]Epoch 4:  79%|███████▉  | 23/29 [00:38<00:08,  1.43s/it, loss=0.4712, lr=0.000000]Epoch 4:  79%|███████▉  | 23/29 [00:39<00:08,  1.43s/it, loss=0.4727, lr=0.000000]Epoch 4:  83%|████████▎ | 24/29 [00:39<00:06,  1.21s/it, loss=0.4727, lr=0.000000]Epoch 4:  83%|████████▎ | 24/29 [00:42<00:06,  1.21s/it, loss=0.4652, lr=0.000000]Epoch 4:  86%|████████▌ | 25/29 [00:42<00:07,  1.75s/it, loss=0.4652, lr=0.000000]Epoch 4:  86%|████████▌ | 25/29 [00:42<00:07,  1.75s/it, loss=0.4834, lr=0.000000]Epoch 4:  90%|████████▉ | 26/29 [00:42<00:03,  1.31s/it, loss=0.4834, lr=0.000000]Epoch 4:  90%|████████▉ | 26/29 [00:43<00:03,  1.31s/it, loss=0.4714, lr=0.000000]Epoch 4:  93%|█████████▎| 27/29 [00:43<00:02,  1.00s/it, loss=0.4714, lr=0.000000]Epoch 4:  93%|█████████▎| 27/29 [00:43<00:02,  1.00s/it, loss=0.4846, lr=0.000000]Epoch 4:  97%|█████████▋| 28/29 [00:43<00:00,  1.27it/s, loss=0.4846, lr=0.000000]Epoch 4:  97%|█████████▋| 28/29 [00:44<00:00,  1.27it/s, loss=0.4720, lr=0.000000]Epoch 4: 100%|██████████| 29/29 [00:44<00:00,  1.19it/s, loss=0.4720, lr=0.000000]Epoch 4: 100%|██████████| 29/29 [00:44<00:00,  1.53s/it, loss=0.4720, lr=0.000000]
Train Loss: 0.4741
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196

Epoch 5/100
Epoch 5:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 5:   0%|          | 0/29 [00:07<?, ?it/s, loss=0.4681, lr=0.000000]Epoch 5:   3%|▎         | 1/29 [00:07<03:19,  7.14s/it, loss=0.4681, lr=0.000000]Epoch 5:   3%|▎         | 1/29 [00:07<03:19,  7.14s/it, loss=0.4720, lr=0.000000]Epoch 5:   7%|▋         | 2/29 [00:07<01:31,  3.37s/it, loss=0.4720, lr=0.000000]Epoch 5:   7%|▋         | 2/29 [00:08<01:31,  3.37s/it, loss=0.4857, lr=0.000000]Epoch 5:  10%|█         | 3/29 [00:08<00:56,  2.16s/it, loss=0.4857, lr=0.000000]Epoch 5:  10%|█         | 3/29 [00:09<00:56,  2.16s/it, loss=0.4851, lr=0.000000]Epoch 5:  14%|█▍        | 4/29 [00:09<00:39,  1.58s/it, loss=0.4851, lr=0.000000]Epoch 5:  14%|█▍        | 4/29 [00:13<00:39,  1.58s/it, loss=0.4694, lr=0.000000]Epoch 5:  17%|█▋        | 5/29 [00:13<00:59,  2.50s/it, loss=0.4694, lr=0.000000]Epoch 5:  17%|█▋        | 5/29 [00:14<00:59,  2.50s/it, loss=0.4707, lr=0.000000]Epoch 5:  21%|██        | 6/29 [00:14<00:43,  1.88s/it, loss=0.4707, lr=0.000000]Epoch 5:  21%|██        | 6/29 [00:14<00:43,  1.88s/it, loss=0.4662, lr=0.000000]Epoch 5:  24%|██▍       | 7/29 [00:14<00:30,  1.37s/it, loss=0.4662, lr=0.000000]Epoch 5:  24%|██▍       | 7/29 [00:14<00:30,  1.37s/it, loss=0.4715, lr=0.000000]Epoch 5:  28%|██▊       | 8/29 [00:14<00:22,  1.06s/it, loss=0.4715, lr=0.000000]Epoch 5:  28%|██▊       | 8/29 [00:18<00:22,  1.06s/it, loss=0.4721, lr=0.000000]Epoch 5:  31%|███       | 9/29 [00:18<00:39,  1.99s/it, loss=0.4721, lr=0.000000]Epoch 5:  31%|███       | 9/29 [00:19<00:39,  1.99s/it, loss=0.4740, lr=0.000000]Epoch 5:  34%|███▍      | 10/29 [00:19<00:29,  1.55s/it, loss=0.4740, lr=0.000000]Epoch 5:  34%|███▍      | 10/29 [00:20<00:29,  1.55s/it, loss=0.4715, lr=0.000000]Epoch 5:  38%|███▊      | 11/29 [00:20<00:23,  1.29s/it, loss=0.4715, lr=0.000000]Epoch 5:  38%|███▊      | 11/29 [00:20<00:23,  1.29s/it, loss=0.4758, lr=0.000000]Epoch 5:  41%|████▏     | 12/29 [00:20<00:17,  1.03s/it, loss=0.4758, lr=0.000000]Epoch 5:  41%|████▏     | 12/29 [00:26<00:17,  1.03s/it, loss=0.4763, lr=0.000000]Epoch 5:  45%|████▍     | 13/29 [00:26<00:40,  2.54s/it, loss=0.4763, lr=0.000000]Epoch 5:  45%|████▍     | 13/29 [00:27<00:40,  2.54s/it, loss=0.4806, lr=0.000000]Epoch 5:  48%|████▊     | 14/29 [00:27<00:29,  1.95s/it, loss=0.4806, lr=0.000000]Epoch 5:  48%|████▊     | 14/29 [00:27<00:29,  1.95s/it, loss=0.4758, lr=0.000000]Epoch 5:  52%|█████▏    | 15/29 [00:27<00:21,  1.51s/it, loss=0.4758, lr=0.000000]Epoch 5:  52%|█████▏    | 15/29 [00:28<00:21,  1.51s/it, loss=0.4770, lr=0.000000]Epoch 5:  55%|█████▌    | 16/29 [00:28<00:16,  1.25s/it, loss=0.4770, lr=0.000000]Epoch 5:  55%|█████▌    | 16/29 [00:31<00:16,  1.25s/it, loss=0.4725, lr=0.000000]Epoch 5:  59%|█████▊    | 17/29 [00:31<00:23,  1.97s/it, loss=0.4725, lr=0.000000]Epoch 5:  59%|█████▊    | 17/29 [00:32<00:23,  1.97s/it, loss=0.4805, lr=0.000000]Epoch 5:  62%|██████▏   | 18/29 [00:32<00:16,  1.52s/it, loss=0.4805, lr=0.000000]Epoch 5:  62%|██████▏   | 18/29 [00:32<00:16,  1.52s/it, loss=0.4789, lr=0.000000]Epoch 5:  66%|██████▌   | 19/29 [00:32<00:11,  1.19s/it, loss=0.4789, lr=0.000000]Epoch 5:  66%|██████▌   | 19/29 [00:33<00:11,  1.19s/it, loss=0.4673, lr=0.000000]Epoch 5:  69%|██████▉   | 20/29 [00:33<00:09,  1.03s/it, loss=0.4673, lr=0.000000]Epoch 5:  69%|██████▉   | 20/29 [00:38<00:09,  1.03s/it, loss=0.4691, lr=0.000000]Epoch 5:  72%|███████▏  | 21/29 [00:38<00:17,  2.14s/it, loss=0.4691, lr=0.000000]Epoch 5:  72%|███████▏  | 21/29 [00:38<00:17,  2.14s/it, loss=0.4743, lr=0.000000]Epoch 5:  76%|███████▌  | 22/29 [00:38<00:11,  1.70s/it, loss=0.4743, lr=0.000000]Epoch 5:  76%|███████▌  | 22/29 [00:39<00:11,  1.70s/it, loss=0.4751, lr=0.000000]Epoch 5:  79%|███████▉  | 23/29 [00:39<00:08,  1.41s/it, loss=0.4751, lr=0.000000]Epoch 5:  79%|███████▉  | 23/29 [00:40<00:08,  1.41s/it, loss=0.4756, lr=0.000000]Epoch 5:  83%|████████▎ | 24/29 [00:40<00:05,  1.19s/it, loss=0.4756, lr=0.000000]Epoch 5:  83%|████████▎ | 24/29 [00:43<00:05,  1.19s/it, loss=0.4786, lr=0.000000]Epoch 5:  86%|████████▌ | 25/29 [00:43<00:07,  1.78s/it, loss=0.4786, lr=0.000000]Epoch 5:  86%|████████▌ | 25/29 [00:43<00:07,  1.78s/it, loss=0.4800, lr=0.000000]Epoch 5:  90%|████████▉ | 26/29 [00:43<00:03,  1.32s/it, loss=0.4800, lr=0.000000]Epoch 5:  90%|████████▉ | 26/29 [00:43<00:03,  1.32s/it, loss=0.4724, lr=0.000000]Epoch 5:  93%|█████████▎| 27/29 [00:43<00:02,  1.00s/it, loss=0.4724, lr=0.000000]Epoch 5:  93%|█████████▎| 27/29 [00:44<00:02,  1.00s/it, loss=0.4682, lr=0.000000]Epoch 5:  97%|█████████▋| 28/29 [00:44<00:00,  1.28it/s, loss=0.4682, lr=0.000000]Epoch 5:  97%|█████████▋| 28/29 [00:44<00:00,  1.28it/s, loss=0.4684, lr=0.000000]Epoch 5: 100%|██████████| 29/29 [00:44<00:00,  1.30it/s, loss=0.4684, lr=0.000000]Epoch 5: 100%|██████████| 29/29 [00:45<00:00,  1.55s/it, loss=0.4684, lr=0.000000]
Train Loss: 0.4742
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196
Saved checkpoint to vit_test_results_20241231_125704/checkpoint_epoch_5.pth

Epoch 6/100
Epoch 6:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 6:   0%|          | 0/29 [00:05<?, ?it/s, loss=0.4819, lr=0.000000]Epoch 6:   3%|▎         | 1/29 [00:05<02:36,  5.57s/it, loss=0.4819, lr=0.000000]Epoch 6:   3%|▎         | 1/29 [00:06<02:36,  5.57s/it, loss=0.4706, lr=0.000000]Epoch 6:   7%|▋         | 2/29 [00:06<01:22,  3.04s/it, loss=0.4706, lr=0.000000]Epoch 6:   7%|▋         | 2/29 [00:07<01:22,  3.04s/it, loss=0.4776, lr=0.000000]Epoch 6:  10%|█         | 3/29 [00:07<00:52,  2.01s/it, loss=0.4776, lr=0.000000]Epoch 6:  10%|█         | 3/29 [00:08<00:52,  2.01s/it, loss=0.4791, lr=0.000000]Epoch 6:  14%|█▍        | 4/29 [00:08<00:38,  1.52s/it, loss=0.4791, lr=0.000000]Epoch 6:  14%|█▍        | 4/29 [00:11<00:38,  1.52s/it, loss=0.4768, lr=0.000000]Epoch 6:  17%|█▋        | 5/29 [00:11<00:50,  2.09s/it, loss=0.4768, lr=0.000000]Epoch 6:  17%|█▋        | 5/29 [00:13<00:50,  2.09s/it, loss=0.4670, lr=0.000000]Epoch 6:  21%|██        | 6/29 [00:13<00:44,  1.92s/it, loss=0.4670, lr=0.000000]Epoch 6:  21%|██        | 6/29 [00:13<00:44,  1.92s/it, loss=0.4754, lr=0.000000]Epoch 6:  24%|██▍       | 7/29 [00:13<00:33,  1.51s/it, loss=0.4754, lr=0.000000]Epoch 6:  24%|██▍       | 7/29 [00:14<00:33,  1.51s/it, loss=0.4732, lr=0.000000]Epoch 6:  28%|██▊       | 8/29 [00:14<00:25,  1.22s/it, loss=0.4732, lr=0.000000]Epoch 6:  28%|██▊       | 8/29 [00:18<00:25,  1.22s/it, loss=0.4660, lr=0.000000]Epoch 6:  31%|███       | 9/29 [00:18<00:41,  2.08s/it, loss=0.4660, lr=0.000000]Epoch 6:  31%|███       | 9/29 [00:20<00:41,  2.08s/it, loss=0.4744, lr=0.000000]Epoch 6:  34%|███▍      | 10/29 [00:20<00:39,  2.10s/it, loss=0.4744, lr=0.000000]Epoch 6:  34%|███▍      | 10/29 [00:21<00:39,  2.10s/it, loss=0.4852, lr=0.000000]Epoch 6:  38%|███▊      | 11/29 [00:21<00:31,  1.73s/it, loss=0.4852, lr=0.000000]Epoch 6:  38%|███▊      | 11/29 [00:21<00:31,  1.73s/it, loss=0.4826, lr=0.000000]Epoch 6:  41%|████▏     | 12/29 [00:21<00:23,  1.40s/it, loss=0.4826, lr=0.000000]Epoch 6:  41%|████▏     | 12/29 [00:24<00:23,  1.40s/it, loss=0.4773, lr=0.000000]Epoch 6:  45%|████▍     | 13/29 [00:24<00:28,  1.81s/it, loss=0.4773, lr=0.000000]Epoch 6:  45%|████▍     | 13/29 [00:25<00:28,  1.81s/it, loss=0.4757, lr=0.000000]Epoch 6:  48%|████▊     | 14/29 [00:25<00:23,  1.59s/it, loss=0.4757, lr=0.000000]Epoch 6:  48%|████▊     | 14/29 [00:26<00:23,  1.59s/it, loss=0.4807, lr=0.000000]Epoch 6:  52%|█████▏    | 15/29 [00:26<00:17,  1.25s/it, loss=0.4807, lr=0.000000]Epoch 6:  52%|█████▏    | 15/29 [00:27<00:17,  1.25s/it, loss=0.4684, lr=0.000000]Epoch 6:  55%|█████▌    | 16/29 [00:27<00:14,  1.09s/it, loss=0.4684, lr=0.000000]Epoch 6:  55%|█████▌    | 16/29 [00:30<00:14,  1.09s/it, loss=0.4739, lr=0.000000]Epoch 6:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it, loss=0.4739, lr=0.000000]Epoch 6:  59%|█████▊    | 17/29 [00:31<00:21,  1.80s/it, loss=0.4710, lr=0.000000]Epoch 6:  62%|██████▏   | 18/29 [00:31<00:18,  1.67s/it, loss=0.4710, lr=0.000000]Epoch 6:  62%|██████▏   | 18/29 [00:32<00:18,  1.67s/it, loss=0.4728, lr=0.000000]Epoch 6:  66%|██████▌   | 19/29 [00:32<00:14,  1.41s/it, loss=0.4728, lr=0.000000]Epoch 6:  66%|██████▌   | 19/29 [00:33<00:14,  1.41s/it, loss=0.4713, lr=0.000000]Epoch 6:  69%|██████▉   | 20/29 [00:33<00:11,  1.23s/it, loss=0.4713, lr=0.000000]Epoch 6:  69%|██████▉   | 20/29 [00:35<00:11,  1.23s/it, loss=0.4694, lr=0.000000]Epoch 6:  72%|███████▏  | 21/29 [00:35<00:12,  1.59s/it, loss=0.4694, lr=0.000000]Epoch 6:  72%|███████▏  | 21/29 [00:37<00:12,  1.59s/it, loss=0.4791, lr=0.000000]Epoch 6:  76%|███████▌  | 22/29 [00:37<00:11,  1.58s/it, loss=0.4791, lr=0.000000]Epoch 6:  76%|███████▌  | 22/29 [00:37<00:11,  1.58s/it, loss=0.4604, lr=0.000000]Epoch 6:  79%|███████▉  | 23/29 [00:37<00:07,  1.27s/it, loss=0.4604, lr=0.000000]Epoch 6:  79%|███████▉  | 23/29 [00:38<00:07,  1.27s/it, loss=0.4765, lr=0.000000]Epoch 6:  83%|████████▎ | 24/29 [00:38<00:05,  1.07s/it, loss=0.4765, lr=0.000000]Epoch 6:  83%|████████▎ | 24/29 [00:41<00:05,  1.07s/it, loss=0.4792, lr=0.000000]Epoch 6:  86%|████████▌ | 25/29 [00:41<00:06,  1.56s/it, loss=0.4792, lr=0.000000]Epoch 6:  86%|████████▌ | 25/29 [00:42<00:06,  1.56s/it, loss=0.4682, lr=0.000000]Epoch 6:  90%|████████▉ | 26/29 [00:42<00:04,  1.43s/it, loss=0.4682, lr=0.000000]Epoch 6:  90%|████████▉ | 26/29 [00:42<00:04,  1.43s/it, loss=0.4699, lr=0.000000]Epoch 6:  93%|█████████▎| 27/29 [00:42<00:02,  1.08s/it, loss=0.4699, lr=0.000000]Epoch 6:  93%|█████████▎| 27/29 [00:42<00:02,  1.08s/it, loss=0.4767, lr=0.000000]Epoch 6:  97%|█████████▋| 28/29 [00:42<00:00,  1.19it/s, loss=0.4767, lr=0.000000]Epoch 6:  97%|█████████▋| 28/29 [00:43<00:00,  1.19it/s, loss=0.4774, lr=0.000000]Epoch 6: 100%|██████████| 29/29 [00:43<00:00,  1.52it/s, loss=0.4774, lr=0.000000]Epoch 6: 100%|██████████| 29/29 [00:43<00:00,  1.49s/it, loss=0.4774, lr=0.000000]
Train Loss: 0.4744
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196

Epoch 7/100
Epoch 7:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 7:   0%|          | 0/29 [00:05<?, ?it/s, loss=0.4696, lr=0.000000]Epoch 7:   3%|▎         | 1/29 [00:05<02:46,  5.95s/it, loss=0.4696, lr=0.000000]Epoch 7:   3%|▎         | 1/29 [00:06<02:46,  5.95s/it, loss=0.4773, lr=0.000000]Epoch 7:   7%|▋         | 2/29 [00:06<01:15,  2.81s/it, loss=0.4773, lr=0.000000]Epoch 7:   7%|▋         | 2/29 [00:07<01:15,  2.81s/it, loss=0.4770, lr=0.000000]Epoch 7:  10%|█         | 3/29 [00:07<00:45,  1.74s/it, loss=0.4770, lr=0.000000]Epoch 7:  10%|█         | 3/29 [00:07<00:45,  1.74s/it, loss=0.4710, lr=0.000000]Epoch 7:  14%|█▍        | 4/29 [00:07<00:33,  1.36s/it, loss=0.4710, lr=0.000000]Epoch 7:  14%|█▍        | 4/29 [00:13<00:33,  1.36s/it, loss=0.4793, lr=0.000000]Epoch 7:  17%|█▋        | 5/29 [00:13<01:08,  2.85s/it, loss=0.4793, lr=0.000000]Epoch 7:  17%|█▋        | 5/29 [00:13<01:08,  2.85s/it, loss=0.4799, lr=0.000000]Epoch 7:  21%|██        | 6/29 [00:13<00:48,  2.11s/it, loss=0.4799, lr=0.000000]Epoch 7:  21%|██        | 6/29 [00:14<00:48,  2.11s/it, loss=0.4793, lr=0.000000]Epoch 7:  24%|██▍       | 7/29 [00:14<00:33,  1.52s/it, loss=0.4793, lr=0.000000]Epoch 7:  24%|██▍       | 7/29 [00:14<00:33,  1.52s/it, loss=0.4832, lr=0.000000]Epoch 7:  28%|██▊       | 8/29 [00:14<00:25,  1.20s/it, loss=0.4832, lr=0.000000]Epoch 7:  28%|██▊       | 8/29 [00:18<00:25,  1.20s/it, loss=0.4767, lr=0.000000]Epoch 7:  31%|███       | 9/29 [00:18<00:39,  2.00s/it, loss=0.4767, lr=0.000000]Epoch 7:  31%|███       | 9/29 [00:19<00:39,  2.00s/it, loss=0.4732, lr=0.000000]Epoch 7:  34%|███▍      | 10/29 [00:19<00:29,  1.57s/it, loss=0.4732, lr=0.000000]Epoch 7:  34%|███▍      | 10/29 [00:19<00:29,  1.57s/it, loss=0.4790, lr=0.000000]Epoch 7:  38%|███▊      | 11/29 [00:19<00:23,  1.30s/it, loss=0.4790, lr=0.000000]Epoch 7:  38%|███▊      | 11/29 [00:20<00:23,  1.30s/it, loss=0.4705, lr=0.000000]Epoch 7:  41%|████▏     | 12/29 [00:20<00:18,  1.06s/it, loss=0.4705, lr=0.000000]Epoch 7:  41%|████▏     | 12/29 [00:24<00:18,  1.06s/it, loss=0.4737, lr=0.000000]Epoch 7:  45%|████▍     | 13/29 [00:24<00:34,  2.15s/it, loss=0.4737, lr=0.000000]Epoch 7:  45%|████▍     | 13/29 [00:25<00:34,  2.15s/it, loss=0.4615, lr=0.000000]Epoch 7:  48%|████▊     | 14/29 [00:25<00:25,  1.72s/it, loss=0.4615, lr=0.000000]Epoch 7:  48%|████▊     | 14/29 [00:26<00:25,  1.72s/it, loss=0.4672, lr=0.000000]Epoch 7:  52%|█████▏    | 15/29 [00:26<00:19,  1.37s/it, loss=0.4672, lr=0.000000]Epoch 7:  52%|█████▏    | 15/29 [00:27<00:19,  1.37s/it, loss=0.4757, lr=0.000000]Epoch 7:  55%|█████▌    | 16/29 [00:27<00:15,  1.17s/it, loss=0.4757, lr=0.000000]Epoch 7:  55%|█████▌    | 16/29 [00:30<00:15,  1.17s/it, loss=0.4795, lr=0.000000]Epoch 7:  59%|█████▊    | 17/29 [00:30<00:24,  2.01s/it, loss=0.4795, lr=0.000000]Epoch 7:  59%|█████▊    | 17/29 [00:31<00:24,  2.01s/it, loss=0.4644, lr=0.000000]Epoch 7:  62%|██████▏   | 18/29 [00:31<00:17,  1.56s/it, loss=0.4644, lr=0.000000]Epoch 7:  62%|██████▏   | 18/29 [00:32<00:17,  1.56s/it, loss=0.4739, lr=0.000000]Epoch 7:  66%|██████▌   | 19/29 [00:32<00:12,  1.30s/it, loss=0.4739, lr=0.000000]Epoch 7:  66%|██████▌   | 19/29 [00:32<00:12,  1.30s/it, loss=0.4720, lr=0.000000]Epoch 7:  69%|██████▉   | 20/29 [00:32<00:10,  1.12s/it, loss=0.4720, lr=0.000000]Epoch 7:  69%|██████▉   | 20/29 [00:37<00:10,  1.12s/it, loss=0.4659, lr=0.000000]Epoch 7:  72%|███████▏  | 21/29 [00:37<00:16,  2.10s/it, loss=0.4659, lr=0.000000]Epoch 7:  72%|███████▏  | 21/29 [00:37<00:16,  2.10s/it, loss=0.4815, lr=0.000000]Epoch 7:  76%|███████▌  | 22/29 [00:37<00:11,  1.68s/it, loss=0.4815, lr=0.000000]Epoch 7:  76%|███████▌  | 22/29 [00:38<00:11,  1.68s/it, loss=0.4783, lr=0.000000]Epoch 7:  79%|███████▉  | 23/29 [00:38<00:08,  1.36s/it, loss=0.4783, lr=0.000000]Epoch 7:  79%|███████▉  | 23/29 [00:39<00:08,  1.36s/it, loss=0.4781, lr=0.000000]Epoch 7:  83%|████████▎ | 24/29 [00:39<00:05,  1.18s/it, loss=0.4781, lr=0.000000]Epoch 7:  83%|████████▎ | 24/29 [00:42<00:05,  1.18s/it, loss=0.4791, lr=0.000000]Epoch 7:  86%|████████▌ | 25/29 [00:42<00:07,  1.86s/it, loss=0.4791, lr=0.000000]Epoch 7:  86%|████████▌ | 25/29 [00:43<00:07,  1.86s/it, loss=0.4874, lr=0.000000]Epoch 7:  90%|████████▉ | 26/29 [00:43<00:04,  1.45s/it, loss=0.4874, lr=0.000000]Epoch 7:  90%|████████▉ | 26/29 [00:43<00:04,  1.45s/it, loss=0.4680, lr=0.000000]Epoch 7:  93%|█████████▎| 27/29 [00:43<00:02,  1.12s/it, loss=0.4680, lr=0.000000]Epoch 7:  93%|█████████▎| 27/29 [00:43<00:02,  1.12s/it, loss=0.4647, lr=0.000000]Epoch 7:  97%|█████████▋| 28/29 [00:43<00:00,  1.16it/s, loss=0.4647, lr=0.000000]Epoch 7:  97%|█████████▋| 28/29 [00:44<00:00,  1.16it/s, loss=0.4622, lr=0.000000]Epoch 7: 100%|██████████| 29/29 [00:44<00:00,  1.13it/s, loss=0.4622, lr=0.000000]Epoch 7: 100%|██████████| 29/29 [00:44<00:00,  1.55s/it, loss=0.4622, lr=0.000000]
Train Loss: 0.4741
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196

Epoch 8/100
Epoch 8:   0%|          | 0/29 [00:00<?, ?it/s]/mnt/guanabana/raid/home/qinxu/land_cover_fraction/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 8:   0%|          | 0/29 [00:07<?, ?it/s, loss=0.4745, lr=0.000000]Epoch 8:   3%|▎         | 1/29 [00:07<03:26,  7.39s/it, loss=0.4745, lr=0.000000]Epoch 8:   3%|▎         | 1/29 [00:08<03:26,  7.39s/it, loss=0.4752, lr=0.000000]Epoch 8:   7%|▋         | 2/29 [00:08<01:32,  3.42s/it, loss=0.4752, lr=0.000000]Epoch 8:   7%|▋         | 2/29 [00:08<01:32,  3.42s/it, loss=0.4836, lr=0.000000]Epoch 8:  10%|█         | 3/29 [00:08<00:57,  2.19s/it, loss=0.4836, lr=0.000000]Epoch 8:  10%|█         | 3/29 [00:09<00:57,  2.19s/it, loss=0.4725, lr=0.000000]Epoch 8:  14%|█▍        | 4/29 [00:09<00:41,  1.66s/it, loss=0.4725, lr=0.000000]Epoch 8:  14%|█▍        | 4/29 [00:13<00:41,  1.66s/it, loss=0.4650, lr=0.000000]Epoch 8:  17%|█▋        | 5/29 [00:13<01:00,  2.54s/it, loss=0.4650, lr=0.000000]Epoch 8:  17%|█▋        | 5/29 [00:14<01:00,  2.54s/it, loss=0.4758, lr=0.000000]Epoch 8:  21%|██        | 6/29 [00:14<00:43,  1.88s/it, loss=0.4758, lr=0.000000]Epoch 8:  21%|██        | 6/29 [00:14<00:43,  1.88s/it, loss=0.4779, lr=0.000000]Epoch 8:  24%|██▍       | 7/29 [00:14<00:32,  1.48s/it, loss=0.4779, lr=0.000000]Epoch 8:  24%|██▍       | 7/29 [00:15<00:32,  1.48s/it, loss=0.4786, lr=0.000000]Epoch 8:  28%|██▊       | 8/29 [00:15<00:25,  1.20s/it, loss=0.4786, lr=0.000000]Epoch 8:  28%|██▊       | 8/29 [00:19<00:25,  1.20s/it, loss=0.4739, lr=0.000000]Epoch 8:  31%|███       | 9/29 [00:19<00:42,  2.12s/it, loss=0.4739, lr=0.000000]Epoch 8:  31%|███       | 9/29 [00:20<00:42,  2.12s/it, loss=0.4634, lr=0.000000]Epoch 8:  34%|███▍      | 10/29 [00:20<00:32,  1.71s/it, loss=0.4634, lr=0.000000]Epoch 8:  34%|███▍      | 10/29 [00:21<00:32,  1.71s/it, loss=0.4717, lr=0.000000]Epoch 8:  38%|███▊      | 11/29 [00:21<00:25,  1.41s/it, loss=0.4717, lr=0.000000]Epoch 8:  38%|███▊      | 11/29 [00:21<00:25,  1.41s/it, loss=0.4797, lr=0.000000]Epoch 8:  41%|████▏     | 12/29 [00:21<00:19,  1.12s/it, loss=0.4797, lr=0.000000]Epoch 8:  41%|████▏     | 12/29 [00:26<00:19,  1.12s/it, loss=0.4743, lr=0.000000]Epoch 8:  45%|████▍     | 13/29 [00:26<00:34,  2.18s/it, loss=0.4743, lr=0.000000]Epoch 8:  45%|████▍     | 13/29 [00:26<00:34,  2.18s/it, loss=0.4737, lr=0.000000]Epoch 8:  48%|████▊     | 14/29 [00:26<00:25,  1.67s/it, loss=0.4737, lr=0.000000]Epoch 8:  48%|████▊     | 14/29 [00:27<00:25,  1.67s/it, loss=0.4702, lr=0.000000]Epoch 8:  52%|█████▏    | 15/29 [00:27<00:19,  1.39s/it, loss=0.4702, lr=0.000000]Epoch 8:  52%|█████▏    | 15/29 [00:28<00:19,  1.39s/it, loss=0.4820, lr=0.000000]Epoch 8:  55%|█████▌    | 16/29 [00:28<00:15,  1.20s/it, loss=0.4820, lr=0.000000]Epoch 8:  55%|█████▌    | 16/29 [00:31<00:15,  1.20s/it, loss=0.4722, lr=0.000000]Epoch 8:  59%|█████▊    | 17/29 [00:31<00:21,  1.79s/it, loss=0.4722, lr=0.000000]Epoch 8:  59%|█████▊    | 17/29 [00:32<00:21,  1.79s/it, loss=0.4671, lr=0.000000]Epoch 8:  62%|██████▏   | 18/29 [00:32<00:16,  1.46s/it, loss=0.4671, lr=0.000000]Epoch 8:  62%|██████▏   | 18/29 [00:32<00:16,  1.46s/it, loss=0.4706, lr=0.000000]Epoch 8:  66%|██████▌   | 19/29 [00:32<00:11,  1.17s/it, loss=0.4706, lr=0.000000]Epoch 8:  66%|██████▌   | 19/29 [00:33<00:11,  1.17s/it, loss=0.4786, lr=0.000000]Epoch 8:  69%|██████▉   | 20/29 [00:33<00:08,  1.02it/s, loss=0.4786, lr=0.000000]Epoch 8:  69%|██████▉   | 20/29 [00:37<00:08,  1.02it/s, loss=0.4760, lr=0.000000]Epoch 8:  72%|███████▏  | 21/29 [00:37<00:16,  2.03s/it, loss=0.4760, lr=0.000000]Epoch 8:  72%|███████▏  | 21/29 [00:38<00:16,  2.03s/it, loss=0.4676, lr=0.000000]Epoch 8:  76%|███████▌  | 22/29 [00:38<00:11,  1.59s/it, loss=0.4676, lr=0.000000]Epoch 8:  76%|███████▌  | 22/29 [00:38<00:11,  1.59s/it, loss=0.4842, lr=0.000000]Epoch 8:  79%|███████▉  | 23/29 [00:38<00:08,  1.35s/it, loss=0.4842, lr=0.000000]Epoch 8:  79%|███████▉  | 23/29 [00:39<00:08,  1.35s/it, loss=0.4812, lr=0.000000]Epoch 8:  83%|████████▎ | 24/29 [00:39<00:05,  1.16s/it, loss=0.4812, lr=0.000000]Epoch 8:  83%|████████▎ | 24/29 [00:43<00:05,  1.16s/it, loss=0.4803, lr=0.000000]Epoch 8:  86%|████████▌ | 25/29 [00:43<00:08,  2.03s/it, loss=0.4803, lr=0.000000]Epoch 8:  86%|████████▌ | 25/29 [00:44<00:08,  2.03s/it, loss=0.4741, lr=0.000000]Epoch 8:  90%|████████▉ | 26/29 [00:44<00:04,  1.58s/it, loss=0.4741, lr=0.000000]Epoch 8:  90%|████████▉ | 26/29 [00:44<00:04,  1.58s/it, loss=0.4678, lr=0.000000]Epoch 8:  93%|█████████▎| 27/29 [00:44<00:02,  1.19s/it, loss=0.4678, lr=0.000000]Epoch 8:  93%|█████████▎| 27/29 [00:44<00:02,  1.19s/it, loss=0.4715, lr=0.000000]Epoch 8:  97%|█████████▋| 28/29 [00:44<00:00,  1.09it/s, loss=0.4715, lr=0.000000]Epoch 8:  97%|█████████▋| 28/29 [00:45<00:00,  1.09it/s, loss=0.4715, lr=0.000000]Epoch 8: 100%|██████████| 29/29 [00:45<00:00,  1.05it/s, loss=0.4715, lr=0.000000]Epoch 8: 100%|██████████| 29/29 [00:46<00:00,  1.59s/it, loss=0.4715, lr=0.000000]
Train Loss: 0.4743
Val Loss: 0.4851
R² scores by fraction:
Fraction 1: -3.8182
Fraction 2: -0.8351
Fraction 3: -0.0977
Fraction 4: -0.8025
Fraction 5: -1.0872
Fraction 6: -159.8767
Fraction 7: -9.7196
early stopping triggered

Training completed!
best validation loss: 0.4851
